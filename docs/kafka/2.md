---
title: kafka客户端操作
date: 2020-12-22
---

## Kafka客户端 API

![image-20201222073315657](https://raw.githubusercontent.com/MilesGO517/images/master/20201222073322.png)

分为5种类型：

- AdminClient API：允许管理和检测Topic、broker以及其它Kafka对象
- Producer API：发布消息到1个或多个topic
- Consumer API：订阅一个或多个topic，并处理产生的消息
- Streams API：高效地将输入流转换到输出流
- Connector API：从一些源系统或应用程序中拉取数据到kafka



## AdminClient API

| API                   | 作用                  |
| --------------------- | --------------------- |
| AdminClient           | AdminClient客户端对象 |
| NewTopic              | 创建Topic             |
| CreateTopicsResult    | 创建Topic的返回结果   |
| ListTopicsResult      | 查询Topic列表         |
| ListTopicsOptions     | 查询Topic列表及选项   |
| DescribeTopicsResult  | 查询Topics            |
| DescribeConfigsResult | 查询Topics配置项      |



## Producer API

Producer发送模式

- 同步发送
- 异步发送
- 异步回调发送



![image-20201222112559996](https://raw.githubusercontent.com/MilesGO517/images/master/20201222112601.png)



![image-20201222113315580](https://raw.githubusercontent.com/MilesGO517/images/master/20201222113316.png)



Kafka Producer

- KafkaProducer，是线程安全的，并不是接到一条发一条，是批量发送的
  - MetricConfig
  - 加载负载均衡器
  - 初始化Serializer
  - 初始化RecordAccumulator，类似于计数器
  - 初始化newSender，守护线程
- producer.send(record)
  - 计算分区，消息具体进入哪一个partition
  - 计算批次，accumulator.append
  - 创建批次、向批次中追加消息



## 消息传递保障

Kafka提供了三种消息传递保障，其依赖于Producer和Consumer共同实现，主要依赖于Producer；

- 最多一次

- 至少一次

- 正好一次

ProducerConfig.ACKS_CONFIG，



实际应用中，不要创建太多producer，甚至每个线程创建1个producer，Kafka的Producer做了批处理，所以我们创建多个producer实例的时候，性能很可能反而不高；



1、Kafka Producer是线程安全的，建议多线程复用，如果每个线程都创建，出现大量的上下文切换或争抢的情况，影响Kafka效率
2、Kafka Producer的key是一个很重要的内容：
    2.1 我们可以根据Key完成Partition的负载均衡
    2.2 合理的Key设计，可以让Flink、Spark Streaming之类的实时分析工具做更快速处理

3、ack - all， kafka层面上就已经有了只有一次的消息投递保障，但是如果想真的不丢数据，最好自行处理异常



消息一定会传送到leader节点，哪怕boot-strap-server不是leader节点；（缓存leader节点的列表）

负载均衡：控制消息去往哪个partition；

异步发送：Future对象，批量发送（阈值：时间、存储上限），减少了IO操作，提高了吞吐量；便于数据Append到日志上（日志操作也可以看成是一种IO）；



## Consumer API

### Consumer group

![image-20201223071652020](https://raw.githubusercontent.com/MilesGO517/images/master/20201223071652.png)



单个分区的消息只能由ConsumerGroup中某个Consumer消费；

也就是说，在同一个ConsumerGroup中的多个Consumer，它们和partition可以是1对多，但不能是多对1；

Consumer从Partition中消费消息是顺序，默认从头开始消费；

单个ConsumerGroup会消费所有Partition中的消息（在没有指定的情况下）；

上图中的这种消费方式是比较推荐的，一个Consumer Group中，Consumer和Partition一对一；



kafka的消费者是线程不安全的；



![image-20201223135732946](https://raw.githubusercontent.com/MilesGO517/images/master/20201223135740.png)



kafka没有单节点的概念，1个节点也视作集群

微信小程序的强制限制：域名+https

